{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921ce3e3-e91a-447a-ae89-f77b07922f75",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition â€“ Preprocessing\n",
    "## Notebook : Group Pipeline\n",
    "\n",
    "**Group Number:** 196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c59f57-aa32-4335-a270-a76c6cb09b90",
   "metadata": {},
   "source": [
    "### Step 01 : Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a19768-213a-42f6-9f0e-83f865b79fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mfcc_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=48000,\n",
    "    n_mfcc=40,\n",
    "    melkwargs={\"n_fft\": 2048, \"hop_length\": 512, \"n_mels\": 128}  # bigger FFT for higher quality\n",
    ").to(device)\n",
    "\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=48000,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    n_mels=128\n",
    ").to(device)\n",
    "\n",
    "def extract_features(file_path):\n",
    "    waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    if sr != 48000:\n",
    "        waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=48000)(waveform)\n",
    "        sr = 48000\n",
    "\n",
    "    waveform = waveform.to(device).squeeze(0)\n",
    "\n",
    "    mfcc = mfcc_transform(waveform.unsqueeze(0)).squeeze()\n",
    "\n",
    "    mel = mel_transform(waveform.unsqueeze(0)).squeeze()\n",
    "\n",
    "    waveform_np = waveform.cpu().numpy()\n",
    "    chroma = librosa.feature.chroma_stft(\n",
    "        y=waveform_np,\n",
    "        sr=sr,\n",
    "        n_fft=2048,\n",
    "        hop_length=512\n",
    "    )\n",
    "    chroma = torch.tensor(chroma, device=device, dtype=torch.float32)\n",
    "\n",
    "    return mfcc, mel, chroma\n",
    "\n",
    "ravdess_dir = \"../data/ravdess\"\n",
    "mfcc_features, mel_features, chroma_features, emotion_labels = [], [], [], []\n",
    "\n",
    "for root, dirs, files in os.walk(ravdess_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            emotion_code = file.split(\"-\")[2]\n",
    "            emotion = emotion_map.get(emotion_code)\n",
    "            if emotion:\n",
    "                try:\n",
    "                    mfcc, mel, chroma = extract_features(file_path)\n",
    "                    \n",
    "                    mfcc_features.append(mfcc)\n",
    "                    mel_features.append(mel)\n",
    "                    chroma_features.append(chroma)\n",
    "                    emotion_labels.append(emotion)\n",
    "                except Exception as e:\n",
    "                    print(\"Error in:\", file_path, e)\n",
    "\n",
    "def pad_feature(extracted_features):\n",
    "    max_length = max(len(sub_feature) for sub_feature in extracted_features)\n",
    "\n",
    "    padded_extracted_features = []\n",
    "    for sub_feature in extracted_features:\n",
    "        padding_needed = max_length - len(sub_feature)\n",
    "\n",
    "        sub_feature_np = np.array(sub_feature)\n",
    "\n",
    "        if padding_needed != 0:\n",
    "            padded_sub_feature = np.pad(sub_feature_np, (0, padding_needed), 'constant', constant_values=0)\n",
    "        else:\n",
    "            padded_sub_feature = sub_feature_np\n",
    "        \n",
    "        padded_extracted_features.append(padded_sub_feature)\n",
    "\n",
    "    return padded_extracted_features\n",
    "\n",
    "padded_mfcc_features = pad_feature(mfcc_features)\n",
    "padded_mel_features = pad_feature(mel_features)\n",
    "padded_chroma_features = pad_feature(chroma_features)\n",
    "\n",
    "mfcc_array = np.hstack(padded_mfcc_features)\n",
    "mel_array = np.hstack(padded_mel_features)\n",
    "chroma_array = np.hstack(padded_chroma_features)\n",
    "\n",
    "os.makedirs(\"../results/features_and_labels\", exist_ok=True)\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30a46a-ff24-4956-8b8e-499491108ee5",
   "metadata": {},
   "source": [
    "### Step 02 : Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec266f7-77ed-4fe1-abd1-634da1a5c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../results/features_and_labels/X_features.npy\", allow_pickle=False)\n",
    "y = np.load(\"../results/features_and_labels/y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"Emotion\"] = y\n",
    "\n",
    "missing_counts = df.drop(columns=\"Emotion\").isnull().sum()\n",
    "\n",
    "features = df.drop(columns=[\"Emotion\"])\n",
    "df[features.columns].fillna(df[features.columns].mean(), inplace=True)\n",
    "\n",
    "X = df.drop(columns=\"Emotion\")\n",
    "y = df[\"Emotion\"]\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09427d2f-ffe1-4c5c-a683-bba536f9fbeb",
   "metadata": {},
   "source": [
    "### Step 03 : Lable Encoding the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33c28c-1d37-4325-a354-6c574306179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../results/features_and_labels/X_features.npy\", allow_pickle=False)\n",
    "y = np.load(\"../results/features_and_labels/y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"Emotion\"] = y\n",
    "\n",
    "unique_emotions, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_label_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "y_mapped = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "X = df.drop(columns=\"Emotion\")\n",
    "y = y_label_encoded\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00eaa9a-acc2-46ac-9716-94821a28e60a",
   "metadata": {},
   "source": [
    "### Step 04 : Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794a89e-1ff9-4807-9444-a02dab55f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../results/features_and_labels/X_features.npy\", allow_pickle=False)\n",
    "y = np.load(\"../results/features_and_labels/y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"Emotion\"] = y\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df.drop(columns=[\"Emotion\"])))\n",
    "\n",
    "outlier_rows_z_score_method = (z_scores > 3).any(axis=1)\n",
    "\n",
    "df_clean_z_score_method = df[~outlier_rows_z_score_method]\n",
    "\n",
    "X = df_clean_z_score_method.drop(columns=\"Emotion\")\n",
    "y = df[\"Emotion\"]\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c97a04-0f42-497a-99cf-e90599224eb7",
   "metadata": {},
   "source": [
    "### Step 05 : Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdab20b-1e40-40de-8a75-8224691566ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../results/features_and_labels/X_features.npy\", allow_pickle=False)\n",
    "y = np.load(\"../results/features_and_labels/y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"Emotion\"] = y\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X = df.drop(columns=\"Emotion\")\n",
    "y = df[\"Emotion\"]\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e37bbe-af51-4ab8-909b-8b4c2dd82784",
   "metadata": {},
   "source": [
    "### Step 06 : Balancing the Dataset by Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541c133-9dbc-40ed-9e86-2e827dd97c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../results/features_and_labels/X_features.npy\", allow_pickle=False)\n",
    "y = np.load(\"../results/features_and_labels/y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "counts = Counter(y)\n",
    "\n",
    "df = pd.DataFrame(list(zip(list(X), y)), columns=[\"Features\", \"Emotion\"])\n",
    "\n",
    "max_size = df[\"Emotion\"].value_counts().max()\n",
    "\n",
    "dfs = []\n",
    "for label, group in df.groupby(\"Emotion\"):\n",
    "    dfs.append(resample(group, replace=True, n_samples=max_size, random_state=42))\n",
    "df_balanced = pd.concat(dfs)\n",
    "\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = df_balanced.drop(columns=\"Emotion\")\n",
    "y = df_balanced[\"Emotion\"]\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58947579-1772-465d-8f2a-58711b1d3a02",
   "metadata": {},
   "source": [
    "### Step 07 : Adding important Data as new Features (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bc0e4-b553-4cc3-b9b9-9fd0a736c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../results/features_and_labels/X_features.npy\", allow_pickle=False)\n",
    "y = np.load(\"../results/features_and_labels/y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"Emotion\"] = y\n",
    "\n",
    "df[\"Feature Mean\"] = df.drop(columns=[\"Emotion\"]).mean(axis=1)\n",
    "df[\"Feature Std\"] = df.drop(columns=[\"Emotion\"]).std(axis=1)\n",
    "df[\"Feature Skewness\"] = df.drop(columns=[\"Emotion\"]).skew(axis=1)\n",
    "df[\"Feature Kurtosis\"] = df.drop(columns=[\"Emotion\"]).kurt(axis=1)\n",
    "\n",
    "X = df.drop(columns=\"Emotion\")\n",
    "y = df[\"Emotion\"]\n",
    "\n",
    "np.save(\"../results/features_and_labels/X_features.npy\", X)\n",
    "np.save(\"../results/features_and_labels/y_labels.npy\", y)\n",
    "\n",
    "print(\"Saved X_features.npy and y_labels.npy to ../results/features_and_labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ba065-ceeb-449f-ba62-d9f23e117b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
